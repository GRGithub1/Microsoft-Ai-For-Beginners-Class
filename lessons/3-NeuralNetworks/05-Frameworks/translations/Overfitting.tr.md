# AÅŸÄ±rÄ± Ã–ÄŸrenme

AÅŸÄ±rÄ± Ã¶ÄŸrenme, makine Ã¶ÄŸrenmesinde son derece Ã¶nemli bir kavramdÄ±r ve bunu doÄŸru yapmak Ã§ok Ã¶nemlidir!

AÅŸaÄŸÄ±daki 5 noktayÄ± (aÅŸaÄŸÄ±daki grafiklerde `x` ile temsil edilen) yaklaÅŸÄ±klama problemini gÃ¶z Ã¶nÃ¼nde bulundurun:

![doÄŸrusal](../../images/overfit1.jpg) | ![aÅŸÄ±rÄ± Ã¶ÄŸrenme](../../images/overfit2.jpg)
-------------------------|--------------------------
**DoÄŸrusal model, 2 parametre** | **DoÄŸrusal olmayan model, 7 parametre**
EÄŸitim hatasÄ± = 5.3 | EÄŸitim hatasÄ± = 0
GeÃ§erleme hatasÄ± = 5.1 | GeÃ§erleme hatasÄ± = 20

* Solda iyi bir dÃ¼z doÄŸru yaklaÅŸÄ±mÄ± gÃ¶rÃ¼yoruz. Parametre sayÄ±sÄ± yeterli olduÄŸundan, model nokta daÄŸÄ±lÄ±mÄ±nÄ±n arkasÄ±ndaki fikri doÄŸru alÄ±r.
* SaÄŸdaki model Ã§ok gÃ¼Ã§lÃ¼dÃ¼r. Sadece 5 noktamÄ±z ve modelin 7 parametresi olduÄŸu iÃ§in, kendisini tÃ¼m noktalardan geÃ§ecek ÅŸekilde ayarlayabilir ve hatayÄ± 0 yapar. Ancak bu, modelin verinin arkasÄ±ndaki doÄŸru Ã¶rÃ¼ntÃ¼yÃ¼ anlamasÄ±nÄ± engeller, dolayÄ±sÄ±yla geÃ§erleme hatasÄ± Ã§ok yÃ¼ksektir.

Modelin zenginliÄŸi (parametre sayÄ±sÄ±) ile eÄŸitim Ã¶rneklerinin sayÄ±sÄ± arasÄ±nda doÄŸru bir denge kurmak Ã§ok Ã¶nemlidir.

## AÅŸÄ±rÄ± Ã¶ÄŸrenme neden olur?

  * Yeterli eÄŸitim verisi yoktur.
  * Model Ã§ok gÃ¼Ã§lÃ¼dÃ¼r.
  * Girdi verisinde Ã§ok fazla gÃ¼rÃ¼ltÃ¼ vardÄ±r.

## AÅŸÄ±rÄ± Ã¶ÄŸrenme nasÄ±l tespit edilir?

YukarÄ±daki ÅŸekilden de gÃ¶rebileceÄŸiniz gibi, aÅŸÄ±rÄ± Ã¶ÄŸrenme, Ã§ok dÃ¼ÅŸÃ¼k bir eÄŸitim hatasÄ± ve yÃ¼ksek bir geÃ§erleme hatasÄ± ile tespit edilebilir. Normalde eÄŸitim sÄ±rasÄ±nda hem eÄŸitim hem de geÃ§erleme hatalarÄ±nÄ±n azalmaya baÅŸladÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼rÃ¼z ve ardÄ±ndan bir noktada geÃ§erleme hatasÄ± azalmayÄ± durdurabilir ve yÃ¼kselmeye baÅŸlayabilir. Bu, aÅŸÄ±rÄ± Ã¶ÄŸrenmenin bir iÅŸaretidir ve muhtemelen bu noktada eÄŸitimi durdurmamÄ±z (veya en azÄ±ndan modelin anlÄ±k gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ almamÄ±z) gerektiÄŸinin gÃ¶stergesi olacaktÄ±r.

![aÅŸÄ±rÄ± Ã¶ÄŸrenme](../../images/Overfitting.png)

## AÅŸÄ±rÄ± Ã¶ÄŸrenme nasÄ±l Ã¶nlenir?

AÅŸÄ±rÄ± Ã¶ÄŸrenmenin meydana geldiÄŸini gÃ¶rÃ¼yorsanÄ±z, aÅŸaÄŸÄ±dakilerden birini yapabilirsiniz:

 * EÄŸitim verisinin miktarÄ±nÄ± artÄ±rÄ±n
 * Modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltÄ±n
 * [Hattan dÃ¼ÅŸÃ¼rme](../../../4-ComputerVision/08-TransferLearning/TrainingTricks.md#Dropout) gibi bazÄ± [dÃ¼zenlileÅŸtirme teknikleri](../../../4-ComputerVision/08-TransferLearning/TrainingTricks.md), ki daha sonra ele alacaÄŸÄ±z, kullanÄ±n.

## AÅŸÄ±rÄ± Ã¶ÄŸrenme ve yanlÄ±lÄ±k-varyans Ã¶dÃ¼nleÅŸmesi

AÅŸÄ±rÄ± Ã¶ÄŸrenme aslÄ±nda istatistikte [yanlÄ±lÄ±k-varyans Ã¶dÃ¼nleÅŸmesi](https://en.wikipedia.org/wiki/Bias%E2%80%93variance_tradeoff) adÄ± verilen daha genel bir sorundur. Modelimizde olasÄ± hata kaynaklarÄ±nÄ± gÃ¶z Ã¶nÃ¼ne alÄ±rsak iki tÃ¼r hata gÃ¶rebiliriz:

* **YanlÄ±lÄ±k hatalarÄ±**, algoritmamÄ±zÄ±n eÄŸitim verileri arasÄ±ndaki iliÅŸkiyi doÄŸru ÅŸekilde yakalayamamasÄ±ndan kaynaklanÄ±r. Modelimizin yeterince gÃ¼Ã§lÃ¼ olmamasÄ±ndan (**eksik Ã¶ÄŸrenme**) kaynaklanabilir.
* **Varyans hatalarÄ±**, modelin anlamlÄ± iliÅŸki yerine girdi verilerindeki gÃ¼rÃ¼ltÃ¼yÃ¼ yaklaÅŸÄ±klamasÄ±ndan (**aÅŸÄ±rÄ± Ã¶ÄŸrenme**) kaynaklanÄ±r.

EÄŸitim esnasÄ±nda, yanlÄ±lÄ±k hatasÄ± azalÄ±r (modelimiz verilere yaklaÅŸmayÄ± Ã¶ÄŸrenirken) ve varyans hatasÄ± artar. AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in eÄŸitimi - manuel olarak (aÅŸÄ±rÄ± Ã¶ÄŸrenmeyi tespit ettiÄŸimizde) veya otomatik olarak (dÃ¼zenlileÅŸtirmeyi katarak) durdurmak Ã¶nemlidir.

## VargÄ±lar

Bu derste, en popÃ¼ler iki YZ Ã§erÃ§evesi olan TensorFlow ve PyTorch iÃ§in Ã§eÅŸitli API'ler arasÄ±ndaki farklarÄ± Ã¶ÄŸrendiniz. AyrÄ±ca, Ã§ok Ã¶nemli bir konuyu da Ã¶ÄŸrendiniz, aÅŸÄ±rÄ± Ã¶ÄŸrenme.

## ğŸš€ Kendini SÄ±nama

Ekli defterlerde alt kÄ±sÄ±mda 'gÃ¶revler'i bulacaksÄ±nÄ±z; defterler Ã¼zerinden Ã§alÄ±ÅŸÄ±n ve gÃ¶revleri tamamlayÄ±n.

## [Ders sonrasÄ± sÄ±navÄ±](https://red-field-0a6ddfd03.1.azurestaticapps.net/quiz/205)

## GÃ¶zden GeÃ§irme ve Bireysel Ã‡alÄ±ÅŸma

AÅŸaÄŸÄ±daki konularda biraz araÅŸtÄ±rma yapÄ±n:

- TensorFlow
- PyTorch
- AÅŸÄ±rÄ± Ã¶ÄŸrenme

Kendinize ÅŸu sorularÄ± sorun:

- TensorFlow ve PyTorch arasÄ±ndaki fark nedir?
- AÅŸÄ±rÄ± Ã¶ÄŸrenme ile eksik Ã¶ÄŸrenme arasÄ±ndaki fark nedir?

## [Ã–dev](../lab/README.md)

Bu laboratuvar Ã§alÄ±ÅŸmasÄ±nda, PyTorch veya TensorFlow kullanarak tek ve Ã§ok katmanlÄ± tam baÄŸlÄ± aÄŸlarÄ± kullanarak iki tane sÄ±nÄ±flandÄ±rma problemini Ã§Ã¶zmeniz isteniyor.

* [Talimatlar](../lab/README.md)
* [Not defteri](../lab/LabFrameworks.ipynb)
